<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-Attention" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/10/26/Attention/" class="article-date">
  <time class="dt-published" datetime="2023-10-26T08:00:47.000Z" itemprop="datePublished">2023-10-26</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2023/10/26/Attention/">Attention</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h3><p>Attention即注意力机制，有三个变量分别是q(query), k(key), v(value)，k和v是成对存在的，一个k对应着一个v，然后通过查询q，在这些键值对里进行一系列操作最后得到输出。</p>
<p>先来看个数学公式</p>
<p><img src="/2023/10/26/Attention/attention.jpg"></p>
<p>K是kernel核函数，这里相当于query减去每个键值对的key，以查询与键之间的距离作为权重，通过核函数进行映射，再乘以每个key对应的value，一个q对n对(k,v)进行运算然后相加就是最后想得到的值。通俗地讲，相当于通过查询，与查询内容相近的点权重更大，它的值对最后的结果有着更大的影响。</p>
<p>上面的数学公式只用于理解注意力机制，下面是实际应用</p>
<p>可以用softmax对上述公式进行简化，q与k之间的关系也进行一定的修改</p>
<p><img src="/2023/10/26/Attention/attention2.jpg"></p>
<p>a表示q与k之间的关系，通常有下面俩种</p>
<p>1.Additive Attention</p>
<p>Wk是k乘以h的矩阵,Wq是q乘以h的矩阵，h是一个长为h的向量，这三个都是可以学习的变量</p>
<p><img src="/2023/10/26/Attention/attention3.jpg"></p>
<p>2.Scaled Dot-Product Attention</p>
<p>要用这个q和k必须要有同样的长度，假如它们长度都为d</p>
<p><img src="/2023/10/26/Attention/attention4.jpg"></p>
<h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self Attention"></a>Self Attention</h3><p>Self Attention(自注意力)大概就是输入一串向量，然后每个向量都会与其他向量发生关联，最后生成输出，每个输出都是考虑了所有输入产生的结果，在序列模型里应用广泛，就像下面这张图。</p>
<p><img src="/2023/10/26/Attention/self_attention.jpg"></p>
<p>那么这些向量是如何关联的呢</p>
<p><img src="/2023/10/26/Attention/self_attention2.png"></p>
<p><img src="/2023/10/26/Attention/self_attention3.png"></p>
<p>对输入向量乘以矩阵生成q与k,然后将q与k进行点积生成注意力分数，进行softmax操作代表了当前k对于q的权重，乘v再相加得到的就是最后的输出，每个输出都是这样运算的，这便是自注意力。</p>
<h3 id="Multi-Headed"><a href="#Multi-Headed" class="headerlink" title="Multi-Headed"></a>Multi-Headed</h3><p>一组q,k,v只能得到一种特征表达，使用多组q,k,v就能得到多种特征表达，这就是Multi-headed(多头注意力机制)，然后我们将所有特征拼接在一起，再通过全连接层来降维。</p>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p><img src="/2023/10/26/Attention/transformer.jpg" alt="transformer"></p>
<p>transformer的架构如上图所示，由一个编码器和一个解码器组成</p>
<p>1.编码器</p>
<p>（Position encoding是什么？</p>
<p>self-attention是对整个序列进行计算，忽略了位置信息，在一个句子里面，每个单词都会被提取成 embedding，可以对这些词嵌入(word embedding)加上position encoding来提供位置信息。）</p>
<p>输入单词序列，被提取成embedding，通过Position encoding添加位置信息，进入多头自注意力层，add代表残差连接，Norm表示对该层进行归一化使训练速度更快，接着进入前馈网络，也就是一个全连接层，再次进行add&amp;norm，注意力层能够反复堆叠，进行n次训练，接着把输出信息给解码器。</p>
<p>2.解码器</p>
<p>大部分几乎和编码器一样，Masked Multi-Head Attention进行了稍微修改，比如输入有a1, a2, a3, a4，此时判断b3的输出，它只能够得到a1, a2, a3的输入信息，不能得到a4的输入信息，后面将前面编码器提供的信息作为k和v，自己的信息作为q，再次进行注意力运算，然后最后通过全连接层和softmax输出概率，在字典里概率最高的那个词就是输出。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/10/26/Attention/" data-id="clo87g9gb0000b4t10rfj52uw" data-title="Attention" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/10/26/Attention/">Attention</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>